{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.metrics import r2_score , mean_squared_error , mean_absolute_error,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#from matplotlib import pyplot as plt\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter all the Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read X and Y Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = pd.read_csv(\"../tsrl10000.csv\")\n",
    "#x = x.iloc[:,1:]\n",
    "#\n",
    "#y = pd.read_csv(\"../srlbininfo_10000\",sep =\"\\t\",header =None )\n",
    "#\n",
    "#y = pd.DataFrame(y.iloc[:,1])\n",
    "#y.columns = [\"RL\"]\n",
    "#\n",
    "#df = pd.concat([y,x],axis =1)\n",
    "#\n",
    "#df = df[df.RL < 25] #Ignore values more than 25\n",
    "#y = pd.DataFrame(df.iloc[:,0])\n",
    "#x = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../RL_df_10000.csv\",index = False) #When Memory Problem Just Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../RL_df_10000.csv\")\n",
    "y = pd.DataFrame(df.iloc[:,0])\n",
    "x = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x.shape, y.shape)\n",
    "#display(x.head(2))\n",
    "#display(y.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data to training and Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7981, 3880), (7981, 1), (1996, 3880), (1996, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test= train_test_split(x,y,test_size=0.2)\n",
    "x_train.shape,y_train.shape, x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Starts Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical Linear Regressors\n",
    "###### We used Following 4 Regression Methods First"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **LinearRegression**([…])-->Ordinary least squares Linear Regression. <br>\n",
    "2. **Ridge**([alpha, fit_intercept, …]) -->Linear least squares with l2 regularization.<br>\n",
    "3. **RidgeCV**([alphas, …]) -->Ridge regression with built-in cross-validation.<br>\n",
    "4. **SGDRegressor**([loss, penalty, …]) -->Linear model fitted by minimizing a regularized empirical loss with SGD<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 LinearRegression()\n",
    "class sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Linear _Regression--> \"\n",
    "lr = LinearRegression().fit(x_train,y_train)\n",
    "y_pred = pd.DataFrame(lr.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , lr.intercept_,\"\\n\") ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",lr.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",lr.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",lr.score(x_test,y_pred)) ##\n",
    "    \n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred)) ##\n",
    "    \n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred)) ##\n",
    "print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(lr.predict(x_train))))\n",
    "    \n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred)) ##\n",
    "print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(lr.predict(x_train))))\n",
    "    \n",
    "print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"RL\"],y_pred[0])[0])\n",
    "print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"RL\"],pd.DataFrame(lr.predict(x_train))[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is for Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = lr.predict(x_train)\n",
    "#fig,ax = plt.subplots()\n",
    "#ax.scatter(y_train,y_pred,edgecolor=(\"r\"))\n",
    "#ax.plot([y_train.min(),y_train.max()],[y_train.min(),y_train.max()],\"b\",lw=2)\n",
    "#ax.set_xlabel(\"Measured\")\n",
    "#ax.set_ylabel(\"Predicted\")\n",
    "#plt.show()\n",
    "#\n",
    "#fit(self,X,y[sample_weight])\n",
    "#get_params(self[,deep])\n",
    "#predict(self,X)\n",
    "#score(self,X,Y[,sample_weight])\n",
    "#set_params(self,\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_pred = lr.predict(x_train)\n",
    "#fig,ax = plt.subplots()\n",
    "#ax.scatter(y_train,y_pred,edgecolor=(\"r\"))\n",
    "##ax.plot([y_train.min(),y_train.max()],[y_train.min(),y_train.max()],\"b\",lw=2)\n",
    "#ax.set_xlabel(\"Measured\")\n",
    "#ax.set_ylabel(\"Predicted\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#\n",
    "#print(scaler.fit(x_train))\n",
    "#print(\"Scaler Mean\",scaler.mean_)\n",
    "#print(\"Scaler Variance\",scaler.var_)\n",
    "#\n",
    "#scaled_x_train = scaler.transform(x_train)\n",
    "#scaled_x_test = scaler.transform(x_test)\n",
    "#\n",
    "#slr = linear_model.LinearRegression()\n",
    "#slr.fit(scaled_x_train,y_train)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Coeff_\",slr.coef_)\n",
    "#print(\"intercept_\",slr.intercept_)\n",
    "#print(\"R2 Score for train Set:{:.3f}\".format(slr.score(scaled_x_train,y_train)))\n",
    "#print(\"R2 Score for test set :{:.3f}\".format(slr.score(scaled_x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#poly = PolynomialFeatures(2)\n",
    "#x_train_poly = poly.fit_transform(x_train)\n",
    "#x_test_poly = poly.transform(x_test)\n",
    "#print(x_train.shape , x_train_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this big Data Memory Error Occured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With as many as 306 features in the model it is natural for the model to get quite complex. The model sticks too much to the data and the model has probably learned the background noise which results in high variance while being fit, which leads to **Overfitting**. This results in poor prediction and generalization power when applied o data outside the training set. To overcome this problem **regularization technique** is used. \n",
    "\n",
    "To find the best model, the common method in machine learning is to define a loss or cost function that describes how well the model fits the data. The goal is to find the model that minimzes this loss function. The idea is to penalize this loss function by adding a complexity term that would give a bigger loss for more complex models. \n",
    "\n",
    "**Regularization** allows to shrink the coefficients to zero by introducing a tuning parameter **'lambda'** or **'alpha'**. This ensures:\n",
    "- Shrinking of parameters, therefore it is mostly used to prevent multicollinearity.\n",
    "- Reduces the model complexity by coefficient shrinkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two popular methods used to regularize parameters are:\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "\n",
    "**Ridge Regression:** Ridge regression uses L2 penalty to penalize coefficients. L2 penalty is the penalty equivalent to **square of the magnitude of coefficients** \n",
    "\n",
    "**Lasso Regression:** Lasso regression uses L1 penalty which is the **absolute value of the magnitude of coefficients**\n",
    "\n",
    "Let us apply Ridge and Lasso models to our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Ridge() Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)` **Default**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ||y - Xw||^2_2 + alpha * ||w||^2_2 Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Methods\n",
    "**fit**(self, X, y[, sample_weight])-->Fit Ridge regression model.<br>\n",
    "**get_params**(self[, deep])--> Get parameters for this estimator.<br>\n",
    "**predict**(self, X)--> Predict using the linear model.<br>\n",
    "**score**(self, X, y[, sample_weight])--> Return the coefficient of determination R^2 of the prediction.<br>\n",
    "**set_params**(self, \\*\\*params) --> Set the parameters of this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Ridge -->\"\n",
    "from sklearn.linear_model import Ridge\n",
    "clf_ridge = Ridge(alpha=0.1)\n",
    "clf_ridge.fit(x_test,y_test)\n",
    "y_pred_ridge = pd.DataFrame(clf_ridge.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \", clf_ridge.coef_) \n",
    "print(name + \" Intercept \" , clf_ridge.intercept_,\"\\n\") ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_ridge.score(x_train,y_train))\n",
    "    #Return the coefficient of determination R^2 of the prediction.\n",
    "    \n",
    "print(name + \"Score for test data Set\",clf_ridge.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",clf_ridge.score(x_test,y_pred_ridge)) ##\n",
    "    \n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_ridge)) ##\n",
    "    \n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_ridge)) ##\n",
    "print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(clf_ridge.predict(x_train))))\n",
    "    \n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_ridge)) ##\n",
    "print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(clf_ridge.predict(x_train))))\n",
    "    \n",
    "print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"RL\"],y_pred_ridge[0])[0])\n",
    "print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"RL\"],pd.DataFrame(clf_ridge.predict(x_train))[0])[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 RidgeCV\n",
    "\n",
    "`class sklearn.linear_model.RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, scoring=None, cv=None, gcv_mode=None, store_cv_values=False)`\n",
    "\n",
    "**fit**(self, X, y[, sample_weight]) --> Fit Ridge regression model with cv. <br>\n",
    "\n",
    "**get_params**(self[, deep])--> Get parameters for this estimator. <br>\n",
    "\n",
    "**predict**(self, X)--> Predict using the linear model.<br>\n",
    "\n",
    "**score**(self, X, y[, sample_weight]) --> Return the coefficient of determination R^2 of the prediction.<br>\n",
    "\n",
    "**set_params**(self, \\*\\*params) --> Set the parameters of this estimator.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "name = \"RidgeCV --> \"\n",
    "#Object Creation\n",
    "clf_ridgecv = RidgeCV(alphas= [1e-3, 1e-2, 1e-1, 1]).fit(x_train , y_train)\n",
    "y_pred_ridgecv = pd.DataFrame(clf_ridgecv.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \", clf_ridgecv.coef_) \n",
    "print(name + \" Intercept \" , clf_ridgecv.intercept_,\"\\n\") ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_ridgecv.score(x_train,y_train))\n",
    "#Return the coefficient of determination R^2 of the prediction.\n",
    "print(name + \"Score for test data Set\",clf_ridgecv.score(x_test,y_test))\n",
    "print(name + \"Score for Predictecd data Set\",clf_ridgecv.score(x_test,y_pred_ridgecv)) ##\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_ridgecv)) ##\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_ridgecv)) ##\n",
    "print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(clf_ridgecv.predict(x_train))))\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_ridgecv)) ##\n",
    "print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(clf_ridgecv.predict(x_train))))\n",
    "print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"RL\"],y_pred_ridgecv[0])[0])\n",
    "print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"RL\"],pd.DataFrame(clf_ridgecv.predict(x_train))[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 SGDRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class sklearn.linear_model.SGDRegressor(loss='squared_loss', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods\n",
    "\n",
    "**densify**(self) --> Convert coefficient matrix to dense array format.<br>\n",
    "\n",
    "**fit**(self, X, y[, coef_init, intercept_init, …])--> Fit linear model with Stochastic Gradient Descent.<br>\n",
    "\n",
    "**get_params**(self[, deep])--> Get parameters for this estimator.<br>\n",
    "\n",
    "**partial_fit**(self, X, y[, sample_weight])--> Perform one epoch of stochastic gradient descent on given samples.<br>\n",
    "\n",
    "**predict**(self, X) --> Predict using the linear model<br>\n",
    "\n",
    "**score**(self, X, y[, sample_weight])--> Return the coefficient of determination R^2 of the prediction.<br>\n",
    "\n",
    "**set_params**(self, \\*\\*kwargs)--> Set and validate the parameters of estimator.<br>\n",
    "\n",
    "**sparsify**(self) --> Convert coefficient matrix to sparse format.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "name = \"SGDRegressor-->\"\n",
    "\n",
    "clf_sgd = SGDRegressor(max_iter = 50000, tol = 1e-3)\n",
    "clf_sgd.fit(x_train, y_train)\n",
    "\n",
    "y_pred_sgd =pd.DataFrame(clf_sgd.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor--> Coefficient  [-1.96550340e+09 -1.75182912e+09 -2.00029917e+09 ...  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "SGDRegressor--> Intercept  [2.3216172e+08] \n",
      "\n",
      "********************Accuracy Test Model Fitting ********************\n",
      "SGDRegressor-->Score for train data set : -1.5903759651624195e+18\n",
      "SGDRegressor-->Score for test data Set -2.565535325206744e+18\n",
      "SGDRegressor-->Score for Predictecd data Set 1.0\n",
      "\n",
      "********************R2 Score********************\n",
      "SGDRegressor-->R2 Score for test is =  -2.565535325206744e+18\n",
      "\n",
      "********************Mean Absolute Error********************\n",
      "SGDRegressor-->Mean Absolute Error of Test =  5030084332.135757\n",
      "SGDRegressor-->Mean Absolute Error on Train 4069625781.0098476\n",
      "\n",
      "******************** Mean Squared Error********************\n",
      "SGDRegressor-->Mean Squared Error of Test =  3.889749180437393e+19\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf_ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f215933930d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"****\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" Mean Squared Error\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"****\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"Mean Squared Error of Test = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_sgd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"Mean Squared Error on Train = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_ridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"****\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" Co Relation\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"****\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"Correlation Test Data \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"RL\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_sgd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf_ridge' is not defined"
     ]
    }
   ],
   "source": [
    "print(name +\" Coefficient \", clf_sgd.coef_) \n",
    "print(name + \" Intercept \" , clf_sgd.intercept_,\"\\n\") ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_sgd.score(x_train,y_train))\n",
    "#Return the coefficient of determination R^2 of the prediction.\n",
    "print(name + \"Score for test data Set\",clf_sgd.score(x_test,y_test))\n",
    "print(name + \"Score for Predictecd data Set\",clf_sgd.score(x_test,y_pred_sgd)) ##\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_sgd)) ##\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_sgd)) ##\n",
    "print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(clf_sgd.predict(x_train))))\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_sgd)) ##\n",
    "print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(clf_sgd.predict(x_train))))\n",
    "print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"RL\"],y_pred_sgd[0])[0])\n",
    "print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"RL\"],pd.DataFrame(clf_ridge.predict(x_train))[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Above Method is Use less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ********************** Part 2 **************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressors with variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1.ElasticNet**([alpha, l1_ratio, …]) \n",
    "Linear regression with combined L1 and L2 priors as regularizer.<br>\n",
    "**2.ElasticNetCV**([l1_ratio, eps, …])\n",
    "Elastic Net model with iterative fitting along a regularization path.<br>\n",
    "**3.Lars**([fit_intercept, verbose, …])\n",
    "Least Angle Regression model a.k.a.<br>\n",
    "**4.LarsCV**([fit_intercept, …])\n",
    "Cross-validated Least Angle Regression model.<br>\n",
    "**5.Lasso**([alpha, fit_intercept, …])\n",
    "Linear Model trained with L1 prior as regularizer (aka the Lasso)<br>\n",
    "**6.LassoCV**([eps, n_alphas, …])\n",
    "Lasso linear model with iterative fitting along a regularization path.<br>\n",
    "**7.LassoLars**([alpha, …])\n",
    "Lasso model fit with Least Angle Regression a.k.a.<br>\n",
    "**8.LassoLarsCV**([fit_intercept, …])\n",
    "Cross-validated Lasso, using the LARS algorithm.<br>\n",
    "**9.LassoLarsIC**([criterion, …])\n",
    "Lasso model fit with Lars using BIC or AIC for model selection<br>\n",
    "**10.OrthogonalMatchingPursuit**([…])\n",
    "Orthogonal Matching Pursuit model (OMP) <br>\n",
    "**11.OrthogonalMatchingPursuitCV**([…])\n",
    "Cross-validated Orthogonal Matching Pursuit model (OMP).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.linear_model.**ElasticNet**(alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Methods\n",
    "\n",
    "**fit**(self, X, y[, check_input]) --> Fit model with coordinate descent.\n",
    "\n",
    "**get_params**(self[, deep])--> Get parameters for this estimator.\n",
    "\n",
    "**path**(X, y[, l1_ratio, eps, n_alphas, …])--> Compute elastic net path with coordinate descent.\n",
    "\n",
    "**predict**(self, X)Predict using the linear model.\n",
    "\n",
    "**score**(self, X, y[, sample_weight]) --> Return the coefficient of determination R^2 of the prediction.\n",
    "\n",
    "**set_params**(self, \\*\\*params)--> Set the parameters of this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "name = \"Elastic net--> \"\n",
    "\n",
    "regr_elasticNet = ElasticNet(alpha=0.01,l1_ratio=10,max_iter=50000,random_state=0)\n",
    "regr_elasticNet.fit(x_train , y_train)\n",
    "\n",
    "y_pred_elasticNet = regr_elasticNet.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , clf_ridgecv.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",regr_elasticNet.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",regr_elasticNet.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",regr_elasticNet.score(x_test,y_pred_elasticNet)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_elasticNet)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_elasticNet))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_elasticNet)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ElasticnetCV()   ---------->> **glmnet** in R<<-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.linear_model.**ElasticNetCV**(l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute='auto', max_iter=1000, tol=0.0001, cv=None, copy_X=True, verbose=0, n_jobs=None, positive=False, random_state=None, selection='cyclic')<br>\n",
    "`Elastic Net model with iterative fitting along a regularization path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "name = \"ElasticnetCV --> \"\n",
    "\n",
    "regr_enetcv = ElasticNetCV(cv=10, random_state=0)\n",
    "regr_enetcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred_elasticnetcv = regr_enetcv.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , regr_enetcv.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",regr_enetcv.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",regr_enetcv.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",regr_enetcv.score(x_test,y_pred_elasticnetcv)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_elasticnetcv)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_elasticnetcv))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_elasticnetcv)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Lars() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class sklearn.linear_model.Lars(fit_intercept=True, verbose=False, normalize=True, precompute='auto', n_nonzero_coefs=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True)[source]¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods\n",
    "\n",
    "**fit**(self, X, y[, Xy])-->Fit the model using X, y as training data.\n",
    "\n",
    "**get_params**(self[, deep])--Get parameters for this estimator.\n",
    "\n",
    "**predict**(self, X)--Predict using the linear model.\n",
    "\n",
    "**score**(self, X, y[, sample_weight])--Return the coefficient of determination R^2 of the prediction.\n",
    "\n",
    "**set_params**(self, \\*\\*params)--Set the parameters of this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lars\n",
    "\n",
    "name = \"Lars -->\"\n",
    "reg_lars = Lars()\n",
    "\n",
    "reg_lars.fit(x_train, y_train)\n",
    "\n",
    "y_pred_lars = reg_lars.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , reg_lars.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_lars.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_lars.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",reg_lars.score(x_test,y_pred_lars)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_lars)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_lars))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_lars)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 LarsCV() \n",
    "\n",
    "class sklearn.linear_model.**LarsCV**(fit_intercept=True, verbose=False, max_iter=500, normalize=True, precompute='auto', cv=None, max_n_alphas=1000, n_jobs=None, eps=2.220446049250313e-16, copy_X=True) <br>\n",
    "\n",
    "\n",
    "**fit(self, X, y)** --> Fit the model using X, y as training data.<br>\n",
    "\n",
    "**get_params(self[, deep])** --> Get parameters for this estimator.<br>\n",
    "\n",
    "**predict(self, X)** --> Predict using the linear model.<br>\n",
    "\n",
    "**score(self, X, y[, sample_weight])** --> Return the coefficient of determination R^2 of the prediction.<br>\n",
    "\n",
    "**set_params(self, \\*\\*params)** --> Set the parameters of this estimator.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Library\n",
    "from sklearn.linear_model import LarsCV\n",
    "\n",
    "name = \"LarsCV-->\"\n",
    "\n",
    "reg_larsCV = LarsCV(cv=10).fit(x_train, y_train)\n",
    "\n",
    "y_predict_lars = reg_larsCV.predict(x_test)\n",
    "reg_larsCV.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , reg_lars.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_lars.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_lars.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",reg_lars.score(x_test,y_pred_lars)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_lars)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_lars))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_lars)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Lasso \n",
    "class sklearn.linear_model.**Lasso**(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
    "\n",
    "**(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1** <br>\n",
    "**Linear Model trained with L1 prior as regularizer (aka the Lasso)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "from sklearn.linear_model import Lasso\n",
    "name = \"Lasso --> \"\n",
    "\n",
    "clf_lasso = Lasso(alpha = 0.1).fit(x_train,y_train)\n",
    "\n",
    "y_predict_lasso = clf_lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , clf_lasso.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_lasso.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",clf_lasso.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",clf_lasso.score(x_test,y_pred_lars)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_predict_lasso)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_predict_lasso))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_predict_lasso)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6  Lasso CV\n",
    "\n",
    "**Lasso linear model with iterative fitting along a regularization path.**<br>\n",
    "**(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1**\n",
    "\n",
    "class sklearn.linear_model.**LassoCV**(eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
    "\n",
    "**fit(self, X, y)** --> Fit linear model with coordinate descent <br>\n",
    "**get_params(self[, deep])**--> Get parameters for this estimator.<br>\n",
    "**path(X, y[, eps, n_alphas, alphas, …])**--> Compute Lasso path with coordinate descent<br>\n",
    "**predict(self, X)**--> Predict using the linear model.<br>\n",
    "**score(self, X, y[, sample_weight])** --> Return the coefficient of determination R^2 of the prediction.<br>\n",
    "**set_params(self, \\*\\*params)** -->Set the parameters of this estimator.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library \n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "name = \"LassoCV\"\n",
    "\n",
    "#make a object\n",
    "reg_LassoCV = LassoCV(cv =10 , random_state = 0).fit(x_train,y_train)\n",
    "y_predict_reg_lassoCV = reg_LassoCV.predict(x_test)\n",
    "\n",
    "#alpha value can be passed seprately to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \", reg_LassoCV.coef_) \n",
    "print(name + \" Intercept \" , reg_LassoCV.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_LassoCV.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_LassoCV.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",reg_LassoCV.score(x_test,y_predict_reg_lassoCV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_predict_reg_lassoCV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_predict_reg_lassoCV))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_predict_reg_lassoCV)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 LassoLars\n",
    "class sklearn.linear_model.**LassoLars**(alpha=1.0, fit_intercept=True, verbose=False, normalize=True, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, positive=False)\n",
    "\n",
    "**Lasso model fit with Least Angle Regression a.k.a. Lars\n",
    "It is a Linear Model trained with an L1 prior as regularizer.**\n",
    "\n",
    "**`(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1`**\n",
    "#### Methods\n",
    "* **fit(self, X, y[, Xy])**--> Fit the model using X, y as training data.\n",
    "\n",
    "* **get_params(self[, deep])**--> Get parameters for this estimator.\n",
    "\n",
    "* **predict(self, X)**--> Predict using the linear model.\n",
    "\n",
    "* **score(self, X, y[, sample_weight])**-->Return the coefficient of determination R^2 of the prediction.\n",
    "\n",
    "* **set_params(self, \\*\\*params)**--> Set the parameters of this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Library \n",
    "from sklearn.linear_model import LassoLars\n",
    "name = \"LassoLars -->\"\n",
    "reg_Lasso_lars = LassoLars(alpha = 0.1).fit(x_train, y_train)\n",
    "\n",
    "y_pred_lasso_lars =  reg_Lasso_lars.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",reg_Lasso_lars.coef_) \n",
    "print(name + \" Intercept \" , reg_Lasso_lars.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_Lasso_lars.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_Lasso_lars.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",reg_Lasso_lars.score(x_test,y_predict_reg_lassoCV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_lasso_lars)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_lasso_lars))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_lasso_lars)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 LassoLarsCV\n",
    "**Lasso linear model with iterative fitting along a regularization path**\n",
    "**The best model is selected by cross-validation.**\n",
    "**The optimization objective for Lasso is** \n",
    "\n",
    "**`(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1`**\n",
    "\n",
    "class sklearn.linear_model.**LassoCV**(eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, positive=False, random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "name = \"LassoLars-->\"\n",
    "\n",
    "reg_lassoLarsCV = LassoLarsCV(cv = 10).fit(x_train, y_train)\n",
    "\n",
    "y_pred_lassoLarsCV = reg_lassoLarsCV.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",reg_lassoLarsCV.coef_) \n",
    "print(name + \" Intercept \" , reg_lassoLarsCV.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_lassoLarsCV.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_lassoLarsCV.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",reg_lassoLarsCV.score(x_test,y_pred_lassoLarsCV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_lassoLarsCV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_lassoLarsCV))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_lassoLarsCV)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 LassoLarsIC\n",
    "**Lasso model fit with Lars using `BIC or AIC` for model selection** <br>\n",
    "The optimization objective for Lasso is:<br>\n",
    "**```(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1```**\n",
    "\n",
    "``class sklearn.linear_model.**LassoLarsIC**((criterion='aic', fit_intercept=True, verbose=False, normalize=True, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, positive=False``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Model\n",
    "from sklearn.linear_model import LassoLarsIC \n",
    "name = \"LassoLarsIC-->\"\n",
    "#Create a object\n",
    "reg_LassoLarsIC = LassoLarsIC(criterion='bic').fit(x_train,y_train)\n",
    "\n",
    "y_pred_lassoLarsIC = reg_LassoLarsIC.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",reg_LassoLarsIC.coef_) \n",
    "print(name + \" Intercept \" , reg_LassoLarsIC.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_LassoLarsIC.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_LassoLarsIC.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",reg_LassoLarsIC.score(x_test,y_pred_lassoLarsIC)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_lassoLarsIC)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_lassoLarsIC))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_lassoLarsIC)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10  OrthogonalMatchingPursuit \n",
    "**`Orthogonal Matching Pursuit model (OMP)`**\n",
    "class sklearn.linear_model.**OrthogonalMatchingPursuit**(n_nonzero_coefs=None, tol=None, fit_intercept=True, normalize=True, precompute='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Model\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "\n",
    "name = \"OPM --> \"\n",
    "#Create a Object\n",
    "reg_opm = OrthogonalMatchingPursuit().fit(x_train , y_train)\n",
    "\n",
    "y_pred_opm = reg_opm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",reg_opm.coef_) \n",
    "print(name + \" Intercept \" , reg_opm.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_opm.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_opm.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",reg_opm.score(x_test,y_pred_opm)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_opm)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_opm))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_opm)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 OrthogonalMatchingPursuitCV\n",
    "class sklearn.linear_model.**OrthogonalMatchingPursuitCV**(copy=True, fit_intercept=True, normalize=True, max_iter=None, cv=None, n_jobs=None, verbose=False)\n",
    "**Cross-validated Orthogonal Matching Pursuit model (OMP)**<br>\n",
    "**fit(self, X, y)**--> Fit the model using X, y as training data.<br>\n",
    "**get_params(self[, deep])**--> Get parameters for this estimator.<br>\n",
    "**predict(self, X)**--> Predict using the linear model.<br>\n",
    "**score(self, X, y[, sample_weight])**--> Return the coefficient of determination R^2 of the prediction.<br>\n",
    "**set_params(self, \\*\\*params)**--> Set the parameters of this estimator.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Library\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV\n",
    "\n",
    "name = \"OPM CV -->\"\n",
    "reg_opmCV = OrthogonalMatchingPursuitCV(cv = 10).fit(x_train, y_train)\n",
    "\n",
    "y_pred_opmCV = reg_opmCV.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",reg_opmCV.coef_) \n",
    "print(name + \" Intercept \" , reg_opmCV.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_opmCV.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_opmCV.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",reg_opmCV.score(x_test,y_pred_opm)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_opmCV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_opmCV))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_opmCV)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 . Bayesian Regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ARDRegression --> bayesian ARD regression\n",
    "\n",
    "```class sklearn.linear_model.ARDRegression(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06,\n",
    "lambda_2=1e-06, compute_score=False, threshold_lambda=10000.0, fit_intercept=True, normalize=False, copy_X=True, verbose=False)```\n",
    "\n",
    "http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "name  = \"ARDRegression\"\n",
    "clf_ard = ARDRegression()\n",
    "\n",
    "clf_ard.fit(x_train,y_train)\n",
    "pred_y_ard = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",clf_ard.coef_) \n",
    "print(name + \" Intercept \" , clf_ard.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_ard.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",clf_ard.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",clf_ard.score(x_test,pred_y_ard)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,pred_y_ard)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,pred_y_ard))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,pred_y_ard)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2  BayesianRidge\n",
    "\n",
    "**```class sklearn.linear_model.BayesianRidge(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, \n",
    "lambda_2=1e-06, alpha_init=None, lambda_init=None, compute_score=False, fit_intercept=True, normalize=False, \n",
    "copy_X=True, verbose=False)```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the library\n",
    "from sklearn.linear_modle import BayesianRidge\n",
    "name = \"BayesianRidge\"\n",
    "\n",
    "clf_bay = bayesianRidge().fit(x_train , y_train)\n",
    "\n",
    "y_pred_bay = clf_bay.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",clf_bay.coef_) \n",
    "print(name + \" Intercept \" , clf_bay.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_bay.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",clf_bay.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\", clf_bay.score(x_test,y_pred_bay)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_bay)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_bay))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_bay)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. MultiTask Linear Regressors with variable selection\n",
    "These estimators fit multiple regression problems (or tasks) jointly, while including sparse coefficients.While the inferred coefficients may differ between the tasks, they are constrained to agree on the features that are selected(non-zero coefficients)\n",
    "\n",
    "1. linear_model.**MultiTaskElasticNet([alpha, …])**--> Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer\n",
    "\n",
    "2. linear_model.**MultiTaskElasticNetCV([…])**--> Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
    "\n",
    "3. linear_model.**MultiTaskLasso([alpha, …])**--> Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.\n",
    "\n",
    "4. linear_model.**MultiTaskLassoCV([eps, …])**--> Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 MultiTaskElasticNet\n",
    "class sklearn.linear_model.**MultiTaskElasticNet**(alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, random_state=None, selection='cyclic')\n",
    "\n",
    "**Multi-task ElasticNet Model trained with L1/L2 mixed-norm as regularizer**\n",
    "The optimization objective for MultiTaskElasticNet is : <br>\n",
    "\n",
    "(1 / (2 * n_samples)) * ||Y - XW||_Fro^2 + alpha * l1_ratio * ||W||_21+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
    "<br> where <br>\n",
    "||W||_21 = sum_i sqrt(sum_j w_ij ^ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "\n",
    "name = \"MT_Enet\"\n",
    "reg_MT_Enet = MultiTaskElasticNet(alpha = 0.10).fit(x_train, y_train)\n",
    "\n",
    "y_pred_MT_Enet = reg_MT_Enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",reg_MT_Enet.coef_) \n",
    "print(name + \" Intercept \" , reg_MT_Enet.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_MT_Enet.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_MT_Enet.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\", reg_MT_Enet.score(x_test,y_pred_MT_Enet)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_MT_Enet)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_MT_Enet))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_MT_Enet)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 MultiTaskElasticNetCV \n",
    "class sklearn.linear_model.**MultiTaskElasticNetCV**(l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, max_iter=1000, tol=0.0001, cv=None, copy_X=True, verbose=0, n_jobs=None, random_state=None, selection='cyclic')\n",
    "\n",
    "**Multi-task L1/L2 ElasticNet with built-in cross-validation.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r \"\"\"(1 / (2 * n_samples)) * ||Y - XW||^Fro_2\n",
    "+ alpha * l1_ratio * ||W||_21\n",
    "+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the Model\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "reg_MT_ECV = MultiTaskElasticNetCV(cv =10).fit(x_train , y_train)\n",
    "\n",
    "y_pred_MT_ECV = reg_MT_ECV.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",reg_MT_ECV.coef_) \n",
    "print(name + \" Intercept \" ,reg_MT_ECV.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_MT_ECV.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_MT_ECV.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\", reg_MT_Enet.score(x_test,y_pred_MT_ECV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_MT_ECV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_MT_ECV))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_MT_ECV)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 MultiTaskLasso\n",
    "class sklearn.linear_model.MultiTaskLasso(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, random_state=None, selection='cyclic')\n",
    "\n",
    "The optimization objective for Lasso is:<br>\n",
    "**(1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21**\n",
    "where<br>\n",
    "**||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the Library\n",
    "from sklearn.linear_model import MultiTaskLasso\n",
    "name = \"MT_Lasso\"\n",
    "#Create a object\n",
    "clf_MT_Lasso = MultiTaskLasso(alpha = 0.1).fit(x_train,y_train)\n",
    "\n",
    "y_pred_MT_Lasso = clf_MT_Lasso.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",clf_MT_Lasso.coef_) \n",
    "print(name + \" Intercept \" ,clf_MT_Lasso.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_MT_Lasso.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",clf_MT_Lasso.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\", clf_MT_Lasso.score(x_test,y_pred_MT_Lasso)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_MT_Lasso)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_MT_Lasso))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_MT_Lasso)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 MultiTasklassoCV \n",
    "class sklearn.linear_model.**MultiTaskLassoCV**(eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, random_state=None, selection='cyclic')\n",
    "<br>\n",
    "**Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer**<br>\n",
    "(1 / (2 * n_samples)) * ||Y - XW||^Fro_2 + alpha * ||W||_21\n",
    "<br>\n",
    "Where<br>\n",
    "||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library\n",
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "\n",
    "name = \"MT_LassoCV\"\n",
    "#Create a object\n",
    "reg_MT_LassoCV = MultiTaskLassoCV(cv =10,noise=4, random_state =0).fit(x_train,y_train)\n",
    "\n",
    "y_pred_MT_LassoCV = reg_MT_LassoCV.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",reg_MT_LassoCV.coef_) \n",
    "print(name + \" Intercept \" ,reg_MT_LassoCV.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",reg_MT_LassoCV.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",reg_MT_LassoCV.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\", reg_MT_LassoCV.score(x_test,y_pred_MT_LassoCV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_MT_LassoCV)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_MT_LassoCV))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_MT_LassoCV)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Outlier-robust regressors\n",
    "`Any estimator using the Huber loss would also be robust to outliers, e.g. SGDRegressor with loss='huber'.`\n",
    "\n",
    "1. **linear_model.HuberRegressor([epsilon, …])--> Linear regression model that is robust to outliers.**\n",
    "\n",
    "2. **linear_model.RANSACRegressor([…])--> RANSAC (RANdom SAmple Consensus) algorithm.**\n",
    "\n",
    "3. **linear_model.TheilSenRegressor([…])--> Theil-Sen Estimator: robust multivariate regression model.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 HuberRegressor()\n",
    "`class sklearn.linear_model.HuberRegressor(epsilon=1.35, max_iter=100, alpha=0.0001, warm_start=False, fit_intercept=True, tol=1e-05)`\n",
    "\n",
    "**Methods** <br>\n",
    "\n",
    "**fit(self, X, y[, sample_weight])**--> Fit the model according to the given training data.\n",
    "\n",
    "**get_params(self[, deep])**--> Get parameters for this estimator.\n",
    "\n",
    "**predict(self, X)**--> Predict using the linear model.\n",
    "\n",
    "**score(self, X, y[, sample_weight])**--> Return the coefficient of determination R^2 of the prediction.\n",
    "\n",
    "**set_params(self, \\*\\*params)**--> Set the parameters of this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Library\n",
    "from sklearn.linear_model import HuberRegressor , LinearRegression\n",
    "name = \"HuberRegressor\"\n",
    "\n",
    "huber = HuberRegressor().fit(x_train,y_train)\n",
    "y_pred_huber = huber.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name +\" Coefficient \",huber.coef_) \n",
    "print(name + \" Intercept \" ,huber.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",huber.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",huber.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\", huber.score(x_test,y_pred_huber)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_huber)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_huber))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_huber)) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python import keras\n",
    "#from tensorflow.python.keras.models import Sequential\n",
    "#from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy\n",
    "#import numpy as np\n",
    "#import matplotlib as plt\n",
    "#import pandas as pd\n",
    "#import sklearn\n",
    "#import pydot\n",
    "#import h5py\n",
    "#import tensorflow\n",
    "#from tensorflow import keras\n",
    "##import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"SCIPY_Version\",scipy.__version__)\n",
    "#print(\"Numpy_Version\",np.__version__) #We imported as np so\n",
    "#print(\"matplotlib_Version\",plt.__version__) #we imported as plt so \n",
    "#print(\"pandas_Version\",pd.__version__)\n",
    "#print(\"Sk_learn_Version\",sklearn.__version__)\n",
    "#print(\"pydot_Version\",pydot.__version__)\n",
    "#print(\"h5py_Version\",h5py.__version__)\n",
    "##print(\"theano_Version\",theano.__version__)\n",
    "#print(\"tensorflow_Version\",tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Weather the basic Deep Learning Model is running or Not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.Sequential([\n",
    "#    keras.layers.Flatten(input_shape = (28,28)),\n",
    "#    \n",
    "#    keras.layers.Dense(128, activation = \"relu\",input_shape = [len(x_train)]),\n",
    "#    keras.layers.Dense(10,activation= \"softmax\")\n",
    "#    \n",
    "#    keras.Dense(1)\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "#len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function --> This Measures how ccurate the Model is during training. We want to minimize this function to \"steer\"\n",
    "# the model tight direction\n",
    "\n",
    "# Optimizer --> This is how the model is updated based on the data it sees and its loss function \n",
    "\n",
    "#Metrics --> Used to monitor the training and testing steps\n",
    "#The Following example uses accuracy, the fraction of the images that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda67970ada4b5d499c879aef5e70dc73ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

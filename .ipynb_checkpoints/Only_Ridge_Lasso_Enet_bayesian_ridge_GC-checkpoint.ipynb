{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.metrics import r2_score , mean_squared_error\n",
    "from sklearn.metrics import accuracy_score ,mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on 10000 data is time Consuming so better to test on 1000 data set and if prediction is best then change data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../trgc10000.csv\",nrows = 10000)\n",
    "x = x.iloc[:,1:]\n",
    "y = pd.read_csv(\"../srlbininfo_10000\",sep =\"\\t\",header =None,nrows = 10000)\n",
    "y = pd.DataFrame(y.iloc[:,1])\n",
    "y.columns = [\"GC\"]\n",
    "\n",
    "df = pd.concat([y,x],axis =1)\n",
    "\n",
    "y = pd.DataFrame(df.loc[:,\"GC\"])\n",
    "x = df.iloc[:,1:]  #    \n",
    "\n",
    "#Caution X Column up to 8000 above that outlier and y.GC Less than "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always Check the data shape , df , x ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 10333), (10000, 10332), (10000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,x.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V10323</th>\n",
       "      <th>V10324</th>\n",
       "      <th>V10325</th>\n",
       "      <th>V10326</th>\n",
       "      <th>V10327</th>\n",
       "      <th>V10328</th>\n",
       "      <th>V10329</th>\n",
       "      <th>V10330</th>\n",
       "      <th>V10331</th>\n",
       "      <th>V10332</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.879025</td>\n",
       "      <td>0.687329</td>\n",
       "      <td>0.983194</td>\n",
       "      <td>0.970820</td>\n",
       "      <td>0.900728</td>\n",
       "      <td>0.735702</td>\n",
       "      <td>0.960757</td>\n",
       "      <td>1.074772</td>\n",
       "      <td>1.597032</td>\n",
       "      <td>1.156174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.869801</td>\n",
       "      <td>0.620215</td>\n",
       "      <td>1.008849</td>\n",
       "      <td>0.926203</td>\n",
       "      <td>0.884105</td>\n",
       "      <td>0.884811</td>\n",
       "      <td>1.020117</td>\n",
       "      <td>0.987255</td>\n",
       "      <td>1.335856</td>\n",
       "      <td>1.170143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 10332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.879025  0.687329  0.983194  0.970820  0.900728  0.735702  0.960757   \n",
       "1  0.869801  0.620215  1.008849  0.926203  0.884105  0.884811  1.020117   \n",
       "\n",
       "         V8        V9       V10  ...  V10323  V10324  V10325  V10326  V10327  \\\n",
       "0  1.074772  1.597032  1.156174  ...       0       0       0       0       0   \n",
       "1  0.987255  1.335856  1.170143  ...       0       0       0       0       0   \n",
       "\n",
       "   V10328  V10329  V10330  V10331  V10332  \n",
       "0       0       0       0       0       0  \n",
       "1       0       0       0       0       0  \n",
       "\n",
       "[2 rows x 10332 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19.052706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.772070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GC\n",
       "0  19.052706\n",
       "1  17.772070"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x.head(2))\n",
    "display(y.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= None;x_test = None;y_train = None;y_test = None\n",
    "### 5 Regression \n",
    "clf_ridge = None ; y_pred_ridge = None;\n",
    "clf_lasso = None ; y_pred_lasso = None\n",
    "regr_elasticNet= None ; y_pred_elasticNet = None\n",
    "regr_enetcv = None ;y_pred_elasticnetcv = None \n",
    "clf_bay = None ; y_pred_bay = None ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(size = 0.20 , random_state=50,shuffle = True):\n",
    "    \"size = train size and random state is how the data are mixed and shuffle in to do mixing or not  \"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    global x_train,x_test,y_train, y_test\n",
    "    x_train= None; x_test = None; y_train = None; y_test = None\n",
    "    x_train,x_test,y_train, y_test = train_test_split(x,y,test_size= size,random_state = random_state , shuffle = shuffle)\n",
    "    \n",
    "    #return x_train,x_test,y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test() # Calling The Function with default Parameter\n",
    "#print(y_train.shape)\n",
    "#display(y_train.head(2))\n",
    "#print(x_train.shape)\n",
    "#display(x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create a Function for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Lasso Model to automatically apply in the loop\n",
    "\n",
    "def lasso( alpha=0.5, fit_intercept=True, normalize=False, precompute=False, copy_X=True, \n",
    "                      max_iter=1000, tol=0.0001, warm_start=False, positive=False,selection='cyclic'):\n",
    "    \n",
    "    \"Just Pass Related values only\"\n",
    "    \n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    global x_train,x_test,y_train, y_test , clf_lasso , y_pred_lasso\n",
    "    \n",
    "    clf_lasso = Lasso(alpha=alpha, fit_intercept=fit_intercept , normalize=normalize, precompute=precompute, copy_X=copy_X, \n",
    "                      max_iter=max_iter, tol=tol, warm_start=warm_start, positive=positive,selection=selection).fit(x_train,y_train)\n",
    "    \n",
    "    y_pred_lasso = pd.DataFrame(clf_lasso.predict(x_test))\n",
    "    name = \"Lasso\"\n",
    "    # *****************************************************************\n",
    "    \n",
    "#    print(name +\" Coefficient \", clf_lasso.coef_) \n",
    "#    print(name + \" Intercept \" , clf_lasso.intercept_,\"\\n\") ##\n",
    "#    print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "#    print(name + \"Score for train data set :\",clf_lasso.score(x_train,y_train))\n",
    "#    print(name + \"Score for test data Set\",clf_lasso.score(x_test,y_test))\n",
    "#\n",
    "#    print(name + \"Score for Predictecd data Set\",clf_lasso.score(x_test,y_pred_lasso)) ##\n",
    "#    \n",
    "#    #print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "#    #print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_lasso)) ##\n",
    "#    \n",
    "#    print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "#    print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_lasso)) ##\n",
    "#    print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(clf_lasso.predict(x_train))))\n",
    "#    \n",
    "#    print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "#    print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_lasso)) ##\n",
    "#    print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(clf_lasso.predict(x_train))))\n",
    "#    \n",
    "#    print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "#    print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"GC\"],y_pred_lasso[0])[0])\n",
    "#    print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"GC\"],pd.DataFrame(clf_lasso.predict(x_train))[0])[0])\n",
    "    \n",
    "    clf_lasso.score(x_test,y_test) ,stats.pearsonr(y_test.GC,pd.DataFrame(clf_lasso.predict(x_test))[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function For Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Model to automatically apply in the loop\n",
    "\n",
    "def ridge( alpha = 0.01,copy_X=True,fit_intercept=True, max_iter=None, normalize=False,\n",
    "      random_state=None, solver='auto', tol=0.001):\n",
    "    \"Just Pass alpha value only\"\n",
    "    \n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    global x_train,x_test,y_train, y_test , clf_ridge , y_pred_ridge\n",
    "    \n",
    "    clf_ridge = Ridge(alpha=alpha,copy_X=copy_X,fit_intercept=fit_intercept, max_iter=max_iter, normalize=normalize,\n",
    "      random_state=random_state, solver=solver, tol=tol).fit(x_train,y_train)\n",
    "    \n",
    "    y_pred_ridge = pd.DataFrame(clf_ridge.predict(x_test))\n",
    "    name = \"Ridge\"\n",
    "    # *****************************************************************\n",
    "    print (\"Ridge Regression\")\n",
    "   # print(name +\" Coefficient \", clf_ridge.coef_) \n",
    "#    print(name + \" Intercept \" , clf_ridge.intercept_,\"\\n\") ##\n",
    "#    print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "#    print(name + \"Score for Train data set :\",clf_ridge.score(x_train,y_train))\n",
    "#    print(name + \"Score for Test data Set\",clf_ridge.score(x_test,y_test))\n",
    "    \n",
    "    #print(name + \"Score for Train data set :\",clf_ridge.score(x_train,y_train),\"Test data Set =\",clf_ridge.score(x_test,y_test))\n",
    "    #Return the coefficient of determination R^2 of the prediction.\n",
    "    \n",
    "    \n",
    "\n",
    "#    print(name + \"Score for Predictecd data Set\",clf_ridge.score(x_test,y_pred_ridge)) ##\n",
    "    \n",
    "    #print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "    #print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_ridge)) ##\n",
    "    \n",
    "#    print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "#    print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_ridge)) ##\n",
    "#    print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(clf_ridge.predict(x_train))))\n",
    "    \n",
    "#    print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "#    print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_ridge)) ##\n",
    "#    print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(clf_ridge.predict(x_train))))\n",
    "    \n",
    "#    print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "#    print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"GC\"],y_pred_ridge[0])[0])\n",
    "#    print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"GC\"],pd.DataFrame(clf_ridge.predict(x_train))[0])[0])\n",
    "    \n",
    "    #print(\"Correlation = \",stats.pearsonr(y_train[\"GC\"],pd.DataFrame(clf_ridge.predict(x_train))[0])[0])\n",
    "    \n",
    "    return clf_ridge.score(x_test,y_test) ,stats.pearsonr(y_test.GC,pd.DataFrame(clf_ridge.predict(x_test))[0])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Function for ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enet(alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False,precompute=False, max_iter=1000,\n",
    "         copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic'):\n",
    "    \n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    global x_train,x_test,y_train, y_test , regr_elasticNet, y_pred_elasticNet\n",
    "\n",
    "    name = \"Elastic net--> \"\n",
    "\n",
    "    regr_elasticNet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=fit_intercept, normalize=normalize,\n",
    "                                 precompute=precompute, max_iter=max_iter,copy_X=copy_X, tol=tol, warm_start=warm_start, \n",
    "                                 positive=positive, random_state=random_state, selection=selection)\n",
    "    \n",
    "    regr_elasticNet.fit(x_train , y_train)\n",
    "\n",
    "    y_pred_elasticNet =pd.DataFrame(regr_elasticNet.predict(x_test))\n",
    "    print(\"Elastic Net\")\n",
    "    \n",
    "#    print(name +\" Coefficient \", regr_elasticNet.coef_) \n",
    "#    print(name + \" Intercept \" , regr_elasticNet.intercept_,\"\\n\") ##\n",
    "#    print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "#    print(name + \"Score for train data set :\",regr_elasticNet.score(x_train,y_train))\n",
    "#    #Return the coefficient of determination R^2 of the prediction.\n",
    "#    print(name + \"Score for test data Set\",regr_elasticNet.score(x_test,y_test))\n",
    "#    print(name + \"Score for Predictecd data Set\",regr_elasticNet.score(x_test,y_pred_elasticNet)) ##\n",
    "#    #print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "#    #print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_sgd)) ##\n",
    "#    print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "#    print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_elasticNet)) ##\n",
    "#    print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(regr_elasticNet.predict(x_train))))\n",
    "#    print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "#    print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_elasticNet)) ##\n",
    "#    print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(regr_elasticNet.predict(x_train))))\n",
    "#    print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "#    print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"GC\"],y_pred_elasticNet[0])[0])\n",
    "#    print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"GC\"],pd.DataFrame(regr_elasticNet.predict(x_train))[0])[0])\n",
    "    \n",
    "    return regr_elasticNet.score(x_test,y_test) ,stats.pearsonr(y_test.GC,pd.DataFrame(regr_elasticNet.predict(x_test))[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Elastic NetCV  **** glmnet in R ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enet_cv(l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute='auto',\n",
    "            max_iter=1000, tol=0.0001, cv=None, copy_X=True, verbose=0, n_jobs=None, positive=False, random_state=None,\n",
    "            selection='cyclic'):\n",
    "    \n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    global x_train,x_test,y_train, y_test , regr_enetcv , y_pred_elasticnetcv\n",
    "    name = \"ElasticnetCV --> \"\n",
    "\n",
    "    regr_enetcv = ElasticNetCV(l1_ratio=l1_ratio, eps=eps, n_alphas=n_alphas, alphas=alphas, fit_intercept=fit_intercept,\n",
    "                               normalize=normalize,precompute=precompute, max_iter=max_iter, tol=tol, cv=cv,copy_X=copy_X,\n",
    "                               verbose=verbose, n_jobs=n_jobs,positive=positive, random_state=random_state, selection=selection)\n",
    "    \n",
    "    regr_enetcv.fit(x_train,y_train)\n",
    "\n",
    "    y_pred_elasticnetcv =pd.DataFrame(regr_enetcv.predict(x_test))\n",
    "    print(\"Elastic Net CV\")\n",
    "#    print(name +\" Coefficient \", regr_enetcv.coef_) \n",
    "#    print(name + \" Intercept \" , regr_enetcv.intercept_,\"\\n\") ##\n",
    "#    \n",
    "#    print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "#    print(name + \"Score for train data set :\",regr_enetcv.score(x_train,y_train))\n",
    "#    #Return the coefficient of determination R^2 of the prediction.\n",
    "#    print(name + \"Score for test data Set\",regr_enetcv.score(x_test,y_test))\n",
    "#    print(name + \"Score for Predictecd data Set\",regr_enetcv.score(x_test,y_pred_elasticnetcv)) ##\n",
    "#    \n",
    "#    #print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "#    #print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_elasticnetcv)) ##\n",
    "#    \n",
    "#    print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "#    print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_elasticnetcv)) ##\n",
    "#    print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(regr_enetcv.predict(x_train))))\n",
    "#    print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "#    print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_elasticnetcv)) ##\n",
    "#    print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(regr_enetcv.predict(x_train))))\n",
    "#    print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "#    print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"GC\"],y_pred_elasticnetcv[0])[0])\n",
    "#    print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"GC\"],pd.DataFrame(regr_enetcv.predict(x_train))[0])[0])\n",
    "    \n",
    "    return regr_enetcv.score(x_test,y_test) ,stats.pearsonr(y_test.GC,pd.DataFrame(regr_enetcv.predict(x_test))[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function For Bayesian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_ridge(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06,\n",
    "                compute_score=False, fit_intercept=True, normalize=False,copy_X=True, verbose=False):\n",
    " \n",
    "    from sklearn.linear_model import BayesianRidge\n",
    "    global x_train,x_test,y_train, y_test ,clf_bay , y_pred_bay\n",
    "    \n",
    "    name = \"BayesianRidge\"\n",
    "    clf_bay = BayesianRidge(n_iter=n_iter, tol=tol, alpha_1=alpha_1, alpha_2=alpha_2, lambda_1=lambda_1, lambda_2=lambda_2,\n",
    "                        compute_score=compute_score,fit_intercept=fit_intercept,normalize=normalize,copy_X=copy_X,\n",
    "                            verbose=verbose).fit(x_train , y_train)\n",
    "    \n",
    "    y_pred_bay = pd.DataFrame(clf_bay.predict(x_test))\n",
    "    print(\"Bayesian Ridge\")\n",
    "#    print(name +\"Coefficient \",clf_bay.coef_) \n",
    "#    print(name + \" Intercept \" , clf_bay.intercept_,\"\\n\") ##\n",
    "    print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "    print(name + \"Score for train data set :\",clf_bay.score(x_train,y_train))\n",
    "    #Return the coefficient of determination R^2 of the prediction.\n",
    "    print(name + \"Score for test data Set\",clf_bay.score(x_test,y_test))\n",
    "#    print(name + \"Score for Predictecd data Set\",clf_bay.score(x_test,y_pred_bay)) ##\n",
    "    #print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "    #print(name + \"R2 Score for test is = \", r2_score(y_test,y_pred_bay)) ##\n",
    "#    print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "#    print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_bay)) ##\n",
    "#    print(name +\"Mean Absolute Error on Train\",mean_absolute_error(y_train,pd.DataFrame(clf_bay.predict(x_train))))\n",
    "#    print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "#    print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_bay)) ##\n",
    "#    print(name+\"Mean Squared Error on Train = \",mean_squared_error(y_train,pd.DataFrame(clf_bay.predict(x_train))))\n",
    "#    print(\"\\n\"+\"****\"*5+\" Co Relation\"+\"****\"*5)\n",
    "#    print(name + \"Correlation Test Data \",stats.pearsonr(y_test[\"GC\"],y_pred_bay[0])[0])\n",
    "#    print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"GC\"],pd.DataFrame(clf_bay.predict(x_train))[0])[0])\n",
    "   \n",
    "    return clf_bay.score(x_test,y_test) ,stats.pearsonr(y_test.GC,pd.DataFrame(clf_bay.predict(x_test))[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default \n",
    "train_test(size = 0.2 , random_state=5,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Ridge Function in  with different Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test(size = 0.2 , random_state=5,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression\n",
      "(0.755343190622171, 0.8730904560557753)\n"
     ]
    }
   ],
   "source": [
    "#We have 2 Function \n",
    "train_test(size = 0.2 , random_state=5,shuffle = True)\n",
    "#***********************************************************\n",
    "print(ridge(alpha=0.9,copy_X=True,fit_intercept=True, max_iter=2,\n",
    "            normalize=True,tol= 0.01,solver=\"svd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression\n",
      "(0.7595605781269438, 0.8765296324889017)\n"
     ]
    }
   ],
   "source": [
    "train_test(size = 0.2 , random_state=580,shuffle = True)\n",
    "#***********************************************************\n",
    "print(ridge(alpha=0.9,copy_X=True,fit_intercept=True, max_iter=1, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'sparse_cg', 'cholesky', 'svd' 'lsqr', 'sag' or 'saga'\n",
    "train_test(size = 0.2 , random_state=580,shuffle = True)\n",
    "#***********************************************************\n",
    "print(ridge(alpha=0.9,copy_X=True,fit_intercept=True, max_iter=1, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-35af6c8f5be6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#***********************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m bayesian_ridge(n_iter=300, tol=0.0001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06,compute_score=True,\n\u001b[1;32m----> 4\u001b[1;33m                fit_intercept=True, normalize=True,copy_X=True, verbose=False)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-2753f5b45a47>\u001b[0m in \u001b[0;36mbayesian_ridge\u001b[1;34m(n_iter, tol, alpha_1, alpha_2, lambda_1, lambda_2, compute_score, fit_intercept, normalize, copy_X, verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m     clf_bay = BayesianRidge(n_iter=n_iter, tol=tol, alpha_1=alpha_1, alpha_2=alpha_2, lambda_1=lambda_1, lambda_2=lambda_2,\n\u001b[0;32m      9\u001b[0m                         \u001b[0mcompute_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                             verbose=verbose).fit(x_train , y_train)\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0my_pred_bay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_bay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    223\u001b[0m             coef_, rmse_ = self._update_coef_(X, y, n_samples, n_features,\n\u001b[0;32m    224\u001b[0m                                               \u001b[0mXT_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meigen_vals_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                                               alpha_, lambda_)\n\u001b[0m\u001b[0;32m    226\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[1;31m# compute the log marginal likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\bayes.py\u001b[0m in \u001b[0;36m_update_coef_\u001b[1;34m(self, X, y, n_samples, n_features, XT_y, U, Vh, eigen_vals_, alpha_, lambda_)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             coef_ = np.dot(X.T, np.dot(\n\u001b[1;32m--> 325\u001b[1;33m                 U / (eigen_vals_ + lambda_ / alpha_)[None, :], U.T))\n\u001b[0m\u001b[0;32m    326\u001b[0m             \u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train_test(size = 0.2 , random_state=5,shuffle = True)\n",
    "#***********************************************************\n",
    "bayesian_ridge(n_iter=300, tol=0.0001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06,compute_score=True,\n",
    "               fit_intercept=True, normalize=True,copy_X=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = 0\n",
    "#for i in range(100):\n",
    "    #print(i*10)\n",
    "    #train_test(size = 0.2 , random_state=580,shuffle = True)\n",
    "    #***********************************************************\n",
    "    #ridge(alpha=0.1*i,copy_X=True,fit_intercept=True, max_iter=1000, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "#y_pred_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the   Lasso Regression with seprate Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We have 2 Function \n",
    "#train_test(size=0.10,random_state=580, shuffle=True)\n",
    "#***********************************************************\n",
    "#lasso( alpha=0.01, fit_intercept=True, normalize=False, precompute=False, copy_X=True,max_iter=1000, tol=0.0001,warm_start=False, positive=False,selection='cyclic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net Regression  (Time Consuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test(size = 0.2 , random_state=580,shuffle = True)\n",
    "#***********************************************************\n",
    "enet(alpha=1.0, l1_ratio=0.1, fit_intercept=True, normalize=False,precompute=False, max_iter=1000,\n",
    "         copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Ridge\n",
      "********************Accuracy Test Model Fitting ********************\n",
      "BayesianRidgeScore for train data set : 0.9208549588359637\n",
      "BayesianRidgeScore for test data Set 0.7993800224456576\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-23a3ba425e95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#***********************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m bayesian_ridge(n_iter=100, tol=0.0001, alpha_1=1e-03, alpha_2=1e-03, lambda_1=1e-03, lambda_2=1e-03,compute_score=True,\n\u001b[1;32m----> 4\u001b[1;33m                fit_intercept=True, normalize=True,copy_X=True, verbose=False)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-2753f5b45a47>\u001b[0m in \u001b[0;36mbayesian_ridge\u001b[1;34m(n_iter, tol, alpha_1, alpha_2, lambda_1, lambda_2, compute_score, fit_intercept, normalize, copy_X, verbose)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#    print(name + \"Correlation Original Data \",stats.pearsonr(y_train[\"GC\"],pd.DataFrame(clf_bay.predict(x_train))[0])[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mregr_enetcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregr_enetcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "train_test(size = 0.05 , random_state=580,shuffle = True)\n",
    "#***********************************************************\n",
    "bayesian_ridge(n_iter=100, tol=0.0001, alpha_1=1e-03, alpha_2=1e-03, lambda_1=1e-03, lambda_2=1e-03,compute_score=True,\n",
    "               fit_intercept=True, normalize=True,copy_X=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test(size = 0.20 , random_state=580,shuffle = True)\n",
    "#***********************************************************\n",
    "bayesian_ridge(n_iter=100, tol=0.0001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06,compute_score=True,\n",
    "               fit_intercept=True, normalize=True,copy_X=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verbose True May take long time\n",
    "\n",
    "train_test(size = 0.10 , random_state=580,shuffle = True)\n",
    "#***********************************************************\n",
    "bayesian_ridge(n_iter=100, tol=0.0001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06,compute_score=True,\n",
    "               fit_intercept=True, normalize=True,copy_X=True, verbose=True) #verbose True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test(size = 0.10 , random_state=580,shuffle = True)\n",
    "#***********************************************************\n",
    "bayesian_ridge(n_iter=100, tol=0.0001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06,compute_score=True,\n",
    "               fit_intercept=True, normalize=True,copy_X=True, verbose=False) #verbose True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bay.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net CV ** Glmnet ** R\n",
    "#### take long Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test(size = 0.2 , random_state=580,shuffle = True)\n",
    "##***********************************************************\n",
    "enet_cv(l1_ratio=0.5, eps=0.001, n_alphas=10, alphas=None, fit_intercept=True, normalize=False, precompute='auto',\n",
    "            max_iter=1000, tol=0.0001, cv=5, copy_X=True, verbose=0, n_jobs=None, positive=False, random_state=None,\n",
    "            selection='cyclic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing 900 Data Sets with Our Developed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge.head()\n",
    "test_x = pd.read_csv(\"../trgc900.csv\")\n",
    "test_x = test_x.iloc[:,1:]\n",
    "#\n",
    "test_y = pd.read_csv(\"../ffyrgc900.csv\")\n",
    "test_y = test_y.iloc[:,1:]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with Ridge Reg Pred 0.8792575842031007\n",
      "Correlation with Bay Reg Pred 0.8632766908016796\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation with Ridge Reg Pred\",stats.pearsonr(test_y[\"V1\"],pd.DataFrame(clf_ridge.predict(test_x))[0])[0])\n",
    "print(\"Correlation with Bay Reg Pred\",stats.pearsonr(test_y[\"V1\"],pd.DataFrame(clf_bay.predict(test_x))[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(clf_ridge.predict(test_x))[0].to_csv(\"ridge_pred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      11.703654\n",
       "1      10.747002\n",
       "2      11.386428\n",
       "3       8.614324\n",
       "4      12.668213\n",
       "         ...    \n",
       "895    10.320221\n",
       "896    11.833286\n",
       "897    11.447097\n",
       "898     9.257430\n",
       "899     9.232797\n",
       "Name: 0, Length: 900, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf_ridge.predict(test_x))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.757538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.110057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.760571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.592814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11.492376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>11.506861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>13.772639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>897</td>\n",
       "      <td>12.679488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>898</td>\n",
       "      <td>12.923870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>899</td>\n",
       "      <td>8.862118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1\n",
       "0    11.757538\n",
       "1    12.110057\n",
       "2     8.760571\n",
       "3     8.592814\n",
       "4    11.492376\n",
       "..         ...\n",
       "895  11.506861\n",
       "896  13.772639\n",
       "897  12.679488\n",
       "898  12.923870\n",
       "899   8.862118\n",
       "\n",
       "[900 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda67970ada4b5d499c879aef5e70dc73ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

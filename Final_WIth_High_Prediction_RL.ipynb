{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.metrics import r2_score , mean_squared_error\n",
    "from sklearn.metrics import accuracy_score ,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Length Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../tsrl10000.csv\")\n",
    "x = x.iloc[:,1:]\n",
    "y = pd.read_csv(\"../srlbininfo_10000\",sep =\"\\t\",header =None )\n",
    "\n",
    "y = pd.DataFrame(y.iloc[:,1])\n",
    "y.columns = [\"RL\"]\n",
    "\n",
    "df = pd.concat([y,x],axis =1)\n",
    "\n",
    "df = df[df.RL < 20] #Ignore values more than 25\n",
    "y = pd.DataFrame(df.iloc[:,0])\n",
    "x = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Both data sets into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7347, 3880), (7347, 1), (2450, 3880), (2450, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test= train_test_split(x,y,test_size = 0.25)\n",
    "\n",
    "\n",
    "x_train.shape,y_train.shape, x_test.shape , y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We Only Choose some Methods Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Ridge -->\"\n",
    "from sklearn.linear_model import Ridge\n",
    "clf_ridge = Ridge(alpha=0.3)\n",
    "clf_ridge.fit(x_test,y_test)\n",
    "y_pred_ridge = pd.DataFrame(clf_ridge.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge --> Intercept  [-1755.94320751]\n",
      "********************Accuracy Test Model Fitting ********************\n",
      "Ridge -->Score for train data set : 0.4637413253380196\n",
      "Ridge -->Score for test data Set 0.9902572104399738\n",
      "Ridge -->Score for Predictecd data Set 1.0\n",
      "\n",
      "********************R2 Score********************\n",
      "Ridge -->R2 Score for test is =  0.9902572104399738\n",
      "\n",
      "********************Mean Absolute Error********************\n",
      "Ridge -->Mean Absolute Error of Test =  0.2796690651647151\n",
      "\n",
      "******************** Mean Squared Error********************\n",
      "Ridge -->Mean Squared Error of Test =  0.12950060172858238\n",
      "Ridge -->Correlation  0.9955243267855866\n"
     ]
    }
   ],
   "source": [
    "#print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , clf_ridge.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_ridge.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",clf_ridge.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",clf_ridge.score(x_test,y_pred_ridge)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_ridge)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_ridge))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_ridge)) ##\n",
    "\n",
    "print(name + \"Correlation \",stats.pearsonr(y_test[\"RL\"],y_pred_ridge[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.reset_index(drop=True,inplace=True)\n",
    "#y_test=y_test[\"RL\"]\n",
    "#y_test = pd.DataFrame(y_test)\n",
    "#df = y_test.merge(y_pred_ridge,how = \"outer\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "from sklearn.linear_model import RidgeCV\n",
    "name = \"RidgeCV --> \"\n",
    "#Object Creation\n",
    "clf_ridgecv = RidgeCV(alphas= [1e-3, 1e-2, 1e-1, 1]).fit(x_train , y_train)\n",
    "y_pred_ridgecv = pd.DataFrame(clf_ridgecv.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , clf_ridgecv.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_ridgecv.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",clf_ridge.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",clf_ridge.score(x_test,y_pred_ridge)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_ridge)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_ridge))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_ridge)) ##\n",
    "\n",
    "print(name + \"Correlation \",stats.pearsonr(y_test[\"RL\"],y_pred_ridge[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Ridge\n",
    "\n",
    "### May take long time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "name  = \"ARDRegression\"\n",
    "clf_ard = ARDRegression()\n",
    "\n",
    "clf_ard.fit(x_train,y_train)\n",
    "pred_y_ard = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(name +\" Coefficient \", lr.coef_) \n",
    "print(name + \" Intercept \" , clf_ridge.intercept_) ##\n",
    "print(\"****\"*5+\"Accuracy Test Model Fitting \"+\"****\"*5)\n",
    "print(name + \"Score for train data set :\",clf_ridge.score(x_train,y_train))\n",
    "print(name + \"Score for test data Set\",clf_ridge.score(x_test,y_test))\n",
    "\n",
    "print(name + \"Score for Predictecd data Set\",clf_ridge.score(x_test,y_pred_ridge)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"R2 Score\"+\"****\"*5)\n",
    "print(name + \"R2 Score for test is = \", r2_score(y_test, y_pred_ridge)) ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\"Mean Absolute Error\"+\"****\"*5)\n",
    "print(name+ \"Mean Absolute Error of Test = \", mean_absolute_error(y_test,y_pred_ridge))  ##\n",
    "\n",
    "print(\"\\n\"+\"****\"*5+\" Mean Squared Error\"+\"****\"*5)\n",
    "print(name + \"Mean Squared Error of Test = \",mean_squared_error(y_test,y_pred_ridge)) ##\n",
    "\n",
    "print(name + \"Correlation \",stats.pearsonr(y_test[\"RL\"],y_pred_ridge[0])[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda67970ada4b5d499c879aef5e70dc73ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/34/d5/ce8c17971067c0184c9045112b755be5461d5ce5253ef65a367e1298d7c5/tensorflow-2.1.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.8.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/30/1b7ccde09bf0c535d11f18a574ed7d7572c729a8f754fd568b297be08b61/protobuf-3.11.3-cp37-cp37m-win_amd64.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Collecting gast==0.2.2 (from tensorflow)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/51/046cbc61c7607e5ecead6ff1a9453fba5e7e47a5ea8d608cc7036586a5ef/scipy-1.4.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.8 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/6d/99aba8db04bf58193ed157dfe7e848494b93dd8aa3f6a4d1edfef318779c/grpcio-1.27.2-cp37-cp37m-win_amd64.whl (1.9MB)\n",
      "Collecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.5)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf>=3.8.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl (76kB)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Installing collected packages: opt-einsum, astor, protobuf, termcolor, gast, google-pasta, scipy, grpcio, absl-py, markdown, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow-estimator, keras-applications, keras-preprocessing, tensorflow\n",
      "  Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] 액세스가 거부되었습니다: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\cluster\\\\hierarchy.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-729353ec5751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import Model\n",
    "from __future__ import absolute_import, division, print_function , unicode_literals\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense , Activation\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! #!pip install -q git+https://github.com/tensorflow/docs\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../tsrl900.csv\")\n",
    "y = pd.read_csv(\"../ffyrgc900.csv\")\n",
    "x = x.iloc[:,1:]\n",
    "y = y.iloc[:,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(x.head(2))\n",
    "y.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data set into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test , y_train, y_test = train_test_split(x,y)\n",
    "x_train.shape, y_train.shape , y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.array(x_train)\n",
    "y_ = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = x_train.shape[1]\n",
    "n_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optionally, the First layer can receive an input_shape argument\n",
    "model = Sequential()\n",
    "model.add(Dense(3880,input_shape = (3880,)))\n",
    "model.add(Dense(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code is same as above\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim = 500))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code is same as above\n",
    "model = Sequential()\n",
    "model.add(Dense(32,batch_input_shape = (None,500)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "# Import the Model\n",
    "\n",
    "n_inputs = x_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(n_inputs))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(100,activation = \"relu\"))\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"Nadam\",\n",
    "    loss = \"mean_squared_error\",\n",
    "    metrics=None,\n",
    "    loss_weights=None,\n",
    "    sample_weight_mode = None,\n",
    "    weighted_metrics= None,\n",
    "    target_tensors = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* class **Adadelta** : Optimizer that implements the Adadelta algorithm.\n",
    "\n",
    "* class **Adagrad**: Optimizer that implements the Adagrad algorithm.\n",
    "\n",
    "* class **Adam**: Optimizer that implements the Adam algorithm.\n",
    "\n",
    "* class **Adamax**: Optimizer that implements the Adamax algorithm.\n",
    "\n",
    "* class **Ftrl**: Optimizer that implements the FTRL algorithm.\n",
    "\n",
    "* class **Nadam**: Optimizer that implements the NAdam algorithm.\n",
    "\n",
    "* class **Optimizer**: Updated base class for optimizers.\n",
    "\n",
    "* class **RMSprop**: Optimizer that implements the RMSprop algorithm.\n",
    "\n",
    "* class **SGD**: Stochastic gradient descent and momentum optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.array(x_train)\n",
    "y_ = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=None,    #Number of Sample per Gradient size\n",
    "    epochs=5,          #Number of Epoch to train the \n",
    "    verbose=1,          # 0,1 or 2,Verbosity mode , 0 = Silent , 1 = Progress bar , 2 = one line per epoch\n",
    "    callbacks=None,     # For more tf.keras.callbacks See below different options\n",
    "    validation_split=0.0, # Float between 0 and 1, Fraction of Training Data to be used as validation Data\n",
    "    validation_data=None, #data on which the loss and any model metrics at the end of each epoch. like (x_val,y_val)\n",
    "    shuffle=True,        #Boolean weather to shuffle the training data before each epoch\n",
    "    class_weight=None,   # Optional dictionary mapping class indices (integers) to a weight (float) value,\n",
    "    sample_weight=None, #numpy array of Weight for the training samples, Used for weighting the loss function\n",
    "    initial_epoch=0,   #Int,Epochat which to start training(Useful for resuming a previous training run)\n",
    "    steps_per_epoch=None, #Int or None , Number of steps before declaring one epoch\n",
    "    validation_steps=None, #Only relevant if Validation_data is provided \n",
    "    validation_freq=1,   #Only relevant if validation data is provided.Int or collections_abc.Container\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `callbacks`\n",
    "`BaseLogger , CSVLogger , Callback , EarlyStopping , History , LambdaCallback , LearningRateScheduler , ModelCheckpoint , ProgbarLogger , ReduceLROnPlateau , RemoteMonitor , TensorBoard , TerminateOnNan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(x_test,\n",
    "             batch_size = None,\n",
    "             verbose =0,\n",
    "             steps = None, \n",
    "             callbacks = None,\n",
    "             workers =1,\n",
    "             use_multiprocessing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model.evaluate(\n",
    "#      x=None,\n",
    "#      y=None,\n",
    "#      batch_size=None,\n",
    "#      verbose=1,\n",
    "#      sample_weight=None,\n",
    "#      steps=None,\n",
    "#      callbacks=None,\n",
    "#      max_queue_size=10,\n",
    "#      workers=1,\n",
    "#      use_multiprocessing=False\n",
    "#  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    model.save(\n",
    "#        filepath,\n",
    "#        overwrite=True,\n",
    "#        include_optimizer=True,\n",
    "#        save_format=None,\n",
    "#        signatures=None,\n",
    "#        options=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.save_weights(filepath , overwrite = True , save_format = None)\n",
    "#### model.summary(line_length = None, postitions = None , print_fn = None)\n",
    "#### model.test_on_batch(x,y = None , sample_weight = None , reset_metrics = True)\n",
    "#### model.to_jason(**kwargs)\n",
    "#### model.to_yaml(**kwargs)\n",
    "#### model.train_on_batch(x , y = None , sample_weight = None , class_weight =  None , reset_metrics = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda67970ada4b5d499c879aef5e70dc73ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

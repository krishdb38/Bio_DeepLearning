{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Import Model\n",
    "from __future__ import absolute_import, division, print_function , unicode_literals\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q git+https://github.com/tensorflow/docs\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_rl = pd.read_csv(\"../tsrl10000.csv\")\n",
    "# x_rl = x_rl.iloc[:,1:]\n",
    "\n",
    "# x_gc = pd.read_csv(\"../trgc10000.csv\")\n",
    "# x_gc = x_gc.iloc[:,1:]\n",
    "\n",
    "# y = pd.read_csv(\"../rgcbininfo_10000\",sep = \"\\t\",header=None)\n",
    "# y = y.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Add all rows and make a new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_rl[\"Read_length\"] = x_rl.index.map(lambda _ : sum(x_rl.iloc[_,:])/300)\n",
    "# x_rl = x_rl.iloc[:,-1]\n",
    "\n",
    "# x_gc[\"Read_Count\"] = x_gc.index.map(lambda _ : sum(x_gc.iloc[_, :]) / 80)\n",
    "# x_gc = x_gc.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the data so we can read later for fast processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a single data Frame\n",
    "# df = pd.concat([x_rl, x_gc ,y], ignore_index = True,axis = 1)\n",
    "# df.columns = [\"Read_length\", \"GC_count\", \"FF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# df.to_csv(\"../read_length_gc_count_ff.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"../read_length_gc_count_ff.csv\")\n",
    "y = df.loc[:,[\"FF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Read_length</th>\n",
       "      <th>GC_count</th>\n",
       "      <th>FF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.210215</td>\n",
       "      <td>111.232844</td>\n",
       "      <td>19.052706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.206084</td>\n",
       "      <td>111.340903</td>\n",
       "      <td>17.772070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.189647</td>\n",
       "      <td>111.400369</td>\n",
       "      <td>16.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.192131</td>\n",
       "      <td>111.153783</td>\n",
       "      <td>14.987733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.196457</td>\n",
       "      <td>111.273290</td>\n",
       "      <td>17.656184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.154905</td>\n",
       "      <td>111.043795</td>\n",
       "      <td>7.967291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.138693</td>\n",
       "      <td>111.033168</td>\n",
       "      <td>7.849717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.181857</td>\n",
       "      <td>111.241458</td>\n",
       "      <td>14.039688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.158535</td>\n",
       "      <td>111.100139</td>\n",
       "      <td>10.706711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.199426</td>\n",
       "      <td>111.317688</td>\n",
       "      <td>18.689057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.201124</td>\n",
       "      <td>111.314599</td>\n",
       "      <td>19.317674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.173143</td>\n",
       "      <td>111.068568</td>\n",
       "      <td>7.594432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.181476</td>\n",
       "      <td>111.194699</td>\n",
       "      <td>13.495284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.177093</td>\n",
       "      <td>111.069525</td>\n",
       "      <td>7.273598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.187169</td>\n",
       "      <td>111.065579</td>\n",
       "      <td>10.588152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.156680</td>\n",
       "      <td>111.114904</td>\n",
       "      <td>3.932720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.200110</td>\n",
       "      <td>111.277295</td>\n",
       "      <td>14.655614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.200001</td>\n",
       "      <td>111.286520</td>\n",
       "      <td>15.175794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.195736</td>\n",
       "      <td>111.163705</td>\n",
       "      <td>13.188355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.183318</td>\n",
       "      <td>111.135251</td>\n",
       "      <td>9.421162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Read_length    GC_count         FF\n",
       "0     11.210215  111.232844  19.052706\n",
       "1     11.206084  111.340903  17.772070\n",
       "2     11.189647  111.400369  16.200000\n",
       "3     11.192131  111.153783  14.987733\n",
       "4     11.196457  111.273290  17.656184\n",
       "5     11.154905  111.043795   7.967291\n",
       "6     11.138693  111.033168   7.849717\n",
       "7     11.181857  111.241458  14.039688\n",
       "8     11.158535  111.100139  10.706711\n",
       "9     11.199426  111.317688  18.689057\n",
       "10    11.201124  111.314599  19.317674\n",
       "11    11.173143  111.068568   7.594432\n",
       "12    11.181476  111.194699  13.495284\n",
       "13    11.177093  111.069525   7.273598\n",
       "14    11.187169  111.065579  10.588152\n",
       "15    11.156680  111.114904   3.932720\n",
       "16    11.200110  111.277295  14.655614\n",
       "17    11.200001  111.286520  15.175794\n",
       "18    11.195736  111.163705  13.188355\n",
       "19    11.183318  111.135251   9.421162"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Read_length</th>\n",
       "      <th>GC_count</th>\n",
       "      <th>FF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>11.107329</td>\n",
       "      <td>110.960952</td>\n",
       "      <td>6.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8483</th>\n",
       "      <td>11.107664</td>\n",
       "      <td>111.127965</td>\n",
       "      <td>3.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>11.107726</td>\n",
       "      <td>111.072545</td>\n",
       "      <td>3.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>11.107850</td>\n",
       "      <td>110.980591</td>\n",
       "      <td>3.636070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9179</th>\n",
       "      <td>11.108003</td>\n",
       "      <td>111.005620</td>\n",
       "      <td>4.251046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>11.108193</td>\n",
       "      <td>111.065802</td>\n",
       "      <td>4.066127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>11.108268</td>\n",
       "      <td>111.003063</td>\n",
       "      <td>4.058712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>11.108295</td>\n",
       "      <td>110.937575</td>\n",
       "      <td>8.292924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>11.108299</td>\n",
       "      <td>111.007322</td>\n",
       "      <td>3.035751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8538</th>\n",
       "      <td>11.108349</td>\n",
       "      <td>110.997622</td>\n",
       "      <td>4.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>11.108370</td>\n",
       "      <td>110.952298</td>\n",
       "      <td>3.326144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>11.108663</td>\n",
       "      <td>110.916273</td>\n",
       "      <td>4.976249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>11.108692</td>\n",
       "      <td>110.998529</td>\n",
       "      <td>4.995328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9459</th>\n",
       "      <td>11.108867</td>\n",
       "      <td>111.054378</td>\n",
       "      <td>4.285154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>11.109027</td>\n",
       "      <td>111.015935</td>\n",
       "      <td>4.222853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>11.109043</td>\n",
       "      <td>111.023280</td>\n",
       "      <td>4.378471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9572</th>\n",
       "      <td>11.109165</td>\n",
       "      <td>110.943788</td>\n",
       "      <td>3.748088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>11.109281</td>\n",
       "      <td>111.002882</td>\n",
       "      <td>4.245827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>11.109285</td>\n",
       "      <td>110.972070</td>\n",
       "      <td>4.390826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>11.109306</td>\n",
       "      <td>111.054496</td>\n",
       "      <td>4.347753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>11.109308</td>\n",
       "      <td>111.021063</td>\n",
       "      <td>7.274951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>11.109321</td>\n",
       "      <td>111.073507</td>\n",
       "      <td>4.213129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>11.109405</td>\n",
       "      <td>111.117235</td>\n",
       "      <td>4.442606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>11.109523</td>\n",
       "      <td>111.025624</td>\n",
       "      <td>3.684268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>11.109582</td>\n",
       "      <td>111.171102</td>\n",
       "      <td>3.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>11.109590</td>\n",
       "      <td>110.990222</td>\n",
       "      <td>3.428635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>11.109594</td>\n",
       "      <td>111.003546</td>\n",
       "      <td>5.325500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>11.109620</td>\n",
       "      <td>111.112742</td>\n",
       "      <td>3.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>11.109799</td>\n",
       "      <td>111.104740</td>\n",
       "      <td>4.771455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>11.109924</td>\n",
       "      <td>111.059763</td>\n",
       "      <td>3.050450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>11.109930</td>\n",
       "      <td>111.052662</td>\n",
       "      <td>5.490556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>11.109951</td>\n",
       "      <td>110.997026</td>\n",
       "      <td>4.472394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>11.110167</td>\n",
       "      <td>111.038435</td>\n",
       "      <td>5.334671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7617</th>\n",
       "      <td>11.110300</td>\n",
       "      <td>111.130044</td>\n",
       "      <td>3.298707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>11.110511</td>\n",
       "      <td>110.995063</td>\n",
       "      <td>3.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>11.110636</td>\n",
       "      <td>111.350029</td>\n",
       "      <td>5.075865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>11.110644</td>\n",
       "      <td>111.049417</td>\n",
       "      <td>3.001819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>11.110677</td>\n",
       "      <td>111.092542</td>\n",
       "      <td>3.375598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>11.110891</td>\n",
       "      <td>111.005040</td>\n",
       "      <td>3.660157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>11.111130</td>\n",
       "      <td>111.045374</td>\n",
       "      <td>3.880527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>11.111173</td>\n",
       "      <td>110.812863</td>\n",
       "      <td>3.474120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>11.111334</td>\n",
       "      <td>111.013644</td>\n",
       "      <td>3.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>11.111335</td>\n",
       "      <td>110.968198</td>\n",
       "      <td>3.471559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>11.111350</td>\n",
       "      <td>110.967229</td>\n",
       "      <td>5.156808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>11.111659</td>\n",
       "      <td>111.074040</td>\n",
       "      <td>3.509462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>11.111766</td>\n",
       "      <td>111.000709</td>\n",
       "      <td>3.331737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>11.111792</td>\n",
       "      <td>110.944441</td>\n",
       "      <td>4.058863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>11.111813</td>\n",
       "      <td>111.019290</td>\n",
       "      <td>3.097406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>11.111822</td>\n",
       "      <td>111.110926</td>\n",
       "      <td>3.632443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>11.111827</td>\n",
       "      <td>111.073620</td>\n",
       "      <td>5.706750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Read_length    GC_count        FF\n",
       "3778    11.107329  110.960952  6.080000\n",
       "8483    11.107664  111.127965  3.330000\n",
       "3879    11.107726  111.072545  3.040000\n",
       "1617    11.107850  110.980591  3.636070\n",
       "9179    11.108003  111.005620  4.251046\n",
       "4262    11.108193  111.065802  4.066127\n",
       "9670    11.108268  111.003063  4.058712\n",
       "1270    11.108295  110.937575  8.292924\n",
       "9101    11.108299  111.007322  3.035751\n",
       "8538    11.108349  110.997622  4.070000\n",
       "4439    11.108370  110.952298  3.326144\n",
       "3975    11.108663  110.916273  4.976249\n",
       "1301    11.108692  110.998529  4.995328\n",
       "9459    11.108867  111.054378  4.285154\n",
       "6673    11.109027  111.015935  4.222853\n",
       "4232    11.109043  111.023280  4.378471\n",
       "9572    11.109165  110.943788  3.748088\n",
       "6070    11.109281  111.002882  4.245827\n",
       "2540    11.109285  110.972070  4.390826\n",
       "4007    11.109306  111.054496  4.347753\n",
       "1425    11.109308  111.021063  7.274951\n",
       "2317    11.109321  111.073507  4.213129\n",
       "3595    11.109405  111.117235  4.442606\n",
       "2340    11.109523  111.025624  3.684268\n",
       "7762    11.109582  111.171102  3.190000\n",
       "5868    11.109590  110.990222  3.428635\n",
       "2134    11.109594  111.003546  5.325500\n",
       "2035    11.109620  111.112742  3.977698\n",
       "3940    11.109799  111.104740  4.771455\n",
       "4773    11.109924  111.059763  3.050450\n",
       "1695    11.109930  111.052662  5.490556\n",
       "1995    11.109951  110.997026  4.472394\n",
       "4059    11.110167  111.038435  5.334671\n",
       "7617    11.110300  111.130044  3.298707\n",
       "5059    11.110511  110.995063  3.540000\n",
       "3363    11.110636  111.350029  5.075865\n",
       "1665    11.110644  111.049417  3.001819\n",
       "1610    11.110677  111.092542  3.375598\n",
       "6706    11.110891  111.005040  3.660157\n",
       "4961    11.111130  111.045374  3.880527\n",
       "5222    11.111173  110.812863  3.474120\n",
       "3636    11.111334  111.013644  3.240000\n",
       "6539    11.111335  110.968198  3.471559\n",
       "1996    11.111350  110.967229  5.156808\n",
       "2069    11.111659  111.074040  3.509462\n",
       "955     11.111766  111.000709  3.331737\n",
       "3742    11.111792  110.944441  4.058863\n",
       "4771    11.111813  111.019290  3.097406\n",
       "3211    11.111822  111.110926  3.632443\n",
       "6353    11.111827  111.073620  5.706750"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"Read_length\").iloc[50:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Read_length</th>\n",
       "      <th>GC_count</th>\n",
       "      <th>FF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>11.182093</td>\n",
       "      <td>111.645477</td>\n",
       "      <td>11.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>11.162768</td>\n",
       "      <td>111.654217</td>\n",
       "      <td>14.973567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>11.095913</td>\n",
       "      <td>111.656647</td>\n",
       "      <td>5.042519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>11.112969</td>\n",
       "      <td>111.674753</td>\n",
       "      <td>6.609822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>11.170516</td>\n",
       "      <td>111.704036</td>\n",
       "      <td>18.210904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>11.194482</td>\n",
       "      <td>111.799899</td>\n",
       "      <td>17.504872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>11.192703</td>\n",
       "      <td>111.801871</td>\n",
       "      <td>18.854774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>11.161286</td>\n",
       "      <td>111.817875</td>\n",
       "      <td>14.608380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>11.172433</td>\n",
       "      <td>111.876019</td>\n",
       "      <td>16.599602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>11.166967</td>\n",
       "      <td>111.883740</td>\n",
       "      <td>15.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>11.168824</td>\n",
       "      <td>111.918899</td>\n",
       "      <td>19.476267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>11.171037</td>\n",
       "      <td>111.923232</td>\n",
       "      <td>19.563304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>11.131994</td>\n",
       "      <td>111.939947</td>\n",
       "      <td>5.993541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>11.206623</td>\n",
       "      <td>112.006402</td>\n",
       "      <td>51.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>11.200150</td>\n",
       "      <td>112.072437</td>\n",
       "      <td>19.542886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9368</th>\n",
       "      <td>11.184309</td>\n",
       "      <td>112.388556</td>\n",
       "      <td>21.016162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>11.155822</td>\n",
       "      <td>112.500767</td>\n",
       "      <td>67.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>11.098360</td>\n",
       "      <td>112.780925</td>\n",
       "      <td>4.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>11.083997</td>\n",
       "      <td>112.836002</td>\n",
       "      <td>4.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8324</th>\n",
       "      <td>11.146469</td>\n",
       "      <td>113.044016</td>\n",
       "      <td>16.350000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Read_length    GC_count         FF\n",
       "33      11.182093  111.645477  11.860000\n",
       "1591    11.162768  111.654217  14.973567\n",
       "2026    11.095913  111.656647   5.042519\n",
       "3907    11.112969  111.674753   6.609822\n",
       "3768    11.170516  111.704036  18.210904\n",
       "387     11.194482  111.799899  17.504872\n",
       "362     11.192703  111.801871  18.854774\n",
       "1801    11.161286  111.817875  14.608380\n",
       "2147    11.172433  111.876019  16.599602\n",
       "4287    11.166967  111.883740  15.290000\n",
       "2285    11.168824  111.918899  19.476267\n",
       "2284    11.171037  111.923232  19.563304\n",
       "5338    11.131994  111.939947   5.993541\n",
       "1208    11.206623  112.006402  51.150000\n",
       "567     11.200150  112.072437  19.542886\n",
       "9368    11.184309  112.388556  21.016162\n",
       "2723    11.155822  112.500767  67.940000\n",
       "3852    11.098360  112.780925   4.480000\n",
       "3851    11.083997  112.836002   4.090000\n",
       "8324    11.146469  113.044016  16.350000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"GC_count\").tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.iloc[:,0]\n",
    "x = df.loc[:,[\"Read_length\", \"GC_count\"]]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Read_length</th>\n",
       "      <th>GC_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.210215</td>\n",
       "      <td>111.232844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.206084</td>\n",
       "      <td>111.340903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Read_length    GC_count\n",
       "0    11.210215  111.232844\n",
       "1    11.206084  111.340903"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.052706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.772070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.987733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.656184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FF\n",
       "0  19.052706\n",
       "1  17.772070\n",
       "2  16.200000\n",
       "3  14.987733\n",
       "4  17.656184"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[\"Final\"] = x.index.map(lambda _ : sum(x.iloc[_,:]))/3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(test_size=0.2, random_state = 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state =20)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n",
      "1.0\n",
      "Mean Square Error 4.7827746091792145\n",
      "Mean Absolute Error 1.5204522406078944\n",
      "(0.8424322123388029, 0.0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    final_score =0\n",
    "    x_train, x_test, y_train, y_test = split(random_state=i)\n",
    "    lr = LinearRegression().fit(x_train, y_train)\n",
    "    y_pred = pd.DataFrame(lr.predict(x_test))\n",
    "    \n",
    "    score = lr.score(x_test, y_pred)\n",
    "    if score > final_score:\n",
    "        final_score = score\n",
    "        print(lr.score(x_test, y_pred))\n",
    "        print(\"Mean Square Error\", mean_squared_error(y_test , pd.DataFrame(y_pred)))\n",
    "        print(\"Mean Absolute Error\", mean_absolute_error(y_test , pd.DataFrame(y_pred)))\n",
    "        print(stats.pearsonr(y_test.FF , y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.score(x_test, y_pred))\n",
    "print(\"Mean Square Error\", mean_squared_error(y_test , pd.DataFrame(y_pred)))\n",
    "print(\"Mean Absolute Error\", mean_absolute_error(y_test , pd.DataFrame(y_pred)))\n",
    "print(stats.pearsonr(y_test.FF , y_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train = scaler.transform(x_train)\n",
    "scaled_x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = LinearRegression().fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_pred = slr.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 Score for train set : {:.3f}\".format(slr.score(scaled_x_test,slr_pred)))\n",
    "print(\"Mean Square Error\", mean_squared_error(y_test , pd.DataFrame(slr_pred)))\n",
    "print(\"Mean Absolute Error\", mean_absolute_error(y_test , pd.DataFrame(slr_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "for i in range(100):\n",
    "    \n",
    "    ridge = Ridge(alpha  = 0.1)\n",
    "    ridge.fit(scaled_x_train, y_train)\n",
    "    ridge_pred = ridge.predict(scaled_x_test)\n",
    "    print(\"R2 Score\",ridge.score(scaled_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 Score\",ridge.score(scaled_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data set into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test , y_train, y_test = train_test_split(x,y)\n",
    "x_train.shape, y_train.shape , y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.array(x_train)\n",
    "y_ = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = x_train.shape[1]\n",
    "n_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optionally, the First layer can receive an input_shape argument\n",
    "model = Sequential()\n",
    "model.add(Dense(3880,input_shape = (3880,)))\n",
    "model.add(Dense(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code is same as above\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim = 500))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code is same as above\n",
    "model = Sequential()\n",
    "model.add(Dense(32,batch_input_shape = (None,500)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "# Import the Model\n",
    "\n",
    "n_inputs = x_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(n_inputs))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(100,activation = \"relu\"))\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"Nadam\",\n",
    "    loss = \"mean_squared_error\",\n",
    "    metrics=None,\n",
    "    loss_weights=None,\n",
    "    sample_weight_mode = None,\n",
    "    weighted_metrics= None,\n",
    "    target_tensors = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* class **Adadelta** : Optimizer that implements the Adadelta algorithm.\n",
    "\n",
    "* class **Adagrad**: Optimizer that implements the Adagrad algorithm.\n",
    "\n",
    "* class **Adam**: Optimizer that implements the Adam algorithm.\n",
    "\n",
    "* class **Adamax**: Optimizer that implements the Adamax algorithm.\n",
    "\n",
    "* class **Ftrl**: Optimizer that implements the FTRL algorithm.\n",
    "\n",
    "* class **Nadam**: Optimizer that implements the NAdam algorithm.\n",
    "\n",
    "* class **Optimizer**: Updated base class for optimizers.\n",
    "\n",
    "* class **RMSprop**: Optimizer that implements the RMSprop algorithm.\n",
    "\n",
    "* class **SGD**: Stochastic gradient descent and momentum optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.array(x_train)\n",
    "y_ = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=None,    #Number of Sample per Gradient size\n",
    "    epochs=5,          #Number of Epoch to train the \n",
    "    verbose=1,          # 0,1 or 2,Verbosity mode , 0 = Silent , 1 = Progress bar , 2 = one line per epoch\n",
    "    callbacks=None,     # For more tf.keras.callbacks See below different options\n",
    "    validation_split=0.0, # Float between 0 and 1, Fraction of Training Data to be used as validation Data\n",
    "    validation_data=None, #data on which the loss and any model metrics at the end of each epoch. like (x_val,y_val)\n",
    "    shuffle=True,        #Boolean weather to shuffle the training data before each epoch\n",
    "    class_weight=None,   # Optional dictionary mapping class indices (integers) to a weight (float) value,\n",
    "    sample_weight=None, #numpy array of Weight for the training samples, Used for weighting the loss function\n",
    "    initial_epoch=0,   #Int,Epochat which to start training(Useful for resuming a previous training run)\n",
    "    steps_per_epoch=None, #Int or None , Number of steps before declaring one epoch\n",
    "    validation_steps=None, #Only relevant if Validation_data is provided \n",
    "    validation_freq=1,   #Only relevant if validation data is provided.Int or collections_abc.Container\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `callbacks`\n",
    "`BaseLogger , CSVLogger , Callback , EarlyStopping , History , LambdaCallback , LearningRateScheduler , ModelCheckpoint , ProgbarLogger , ReduceLROnPlateau , RemoteMonitor , TensorBoard , TerminateOnNan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(x_test,\n",
    "             batch_size = None,\n",
    "             verbose =0,\n",
    "             steps = None, \n",
    "             callbacks = None,\n",
    "             workers =1,\n",
    "             use_multiprocessing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model.evaluate(\n",
    "#      x=None,\n",
    "#      y=None,\n",
    "#      batch_size=None,\n",
    "#      verbose=1,\n",
    "#      sample_weight=None,\n",
    "#      steps=None,\n",
    "#      callbacks=None,\n",
    "#      max_queue_size=10,\n",
    "#      workers=1,\n",
    "#      use_multiprocessing=False\n",
    "#  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    model.save(\n",
    "#        filepath,\n",
    "#        overwrite=True,\n",
    "#        include_optimizer=True,\n",
    "#        save_format=None,\n",
    "#        signatures=None,\n",
    "#        options=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.save_weights(filepath , overwrite = True , save_format = None)\n",
    "#### model.summary(line_length = None, postitions = None , print_fn = None)\n",
    "#### model.test_on_batch(x,y = None , sample_weight = None , reset_metrics = True)\n",
    "#### model.to_jason(**kwargs)\n",
    "#### model.to_yaml(**kwargs)\n",
    "#### model.train_on_batch(x , y = None , sample_weight = None , class_weight =  None , reset_metrics = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda67970ada4b5d499c879aef5e70dc73ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
